{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awannabecs/PublicTensorflowRepository/blob/main/CHATBOT**.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### import the will-be-needed modules ####\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "WaCfxSoyIRSm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### load the data ####\n",
        "data_path =  \"/content/DATAFILE/human_text.txt\"\n",
        "data_path2 = \"/content/DATAFILE/robot_text.txt\""
      ],
      "metadata": {
        "id": "32MkE77-Jq6Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path, mode=\"r\",encoding=\"utf-8\") as f :\n",
        "  lines = f.read().split(\"\\n\")\n",
        "\n",
        "with open(data_path2, mode=\"r\", encoding=\"utf-8\") as f :\n",
        "  lines2 = f.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "jAvdkcG5Ksst"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "\n",
        "pairs = list(zip(lines,lines2))\n",
        "\n",
        "random.shuffle(pairs)"
      ],
      "metadata": {
        "id": "wSyFx1hzL1GT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "\n",
        "for line in pairs:\n",
        "  input_doc, target_doc = line[0],line[1]\n",
        "  input_docs.append(input_doc)\n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ],
      "metadata": {
        "id": "ij3bnobqP_S5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())"
      ],
      "metadata": {
        "id": "A2BbCEEpTD5h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum length of sentences in input and target documents\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "encoder_input_data\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        # Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "metadata": {
        "id": "fQ8KRDLQYTY4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 50\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "knF1zRit6EsS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ],
      "metadata": {
        "id": "v6K26xjT76jm",
        "outputId": "53a9fda6-68de-4e2a-ad8e-dae06208666a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "32/32 [==============================] - 69s 2s/step - loss: 0.4783 - accuracy: 0.0183 - val_loss: 0.4923 - val_accuracy: 0.0093\n",
            "Epoch 2/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4614 - accuracy: 0.0092 - val_loss: 0.4904 - val_accuracy: 0.0093\n",
            "Epoch 3/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4581 - accuracy: 0.0092 - val_loss: 0.4882 - val_accuracy: 0.0092\n",
            "Epoch 4/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4557 - accuracy: 0.0091 - val_loss: 0.4880 - val_accuracy: 0.0093\n",
            "Epoch 5/600\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.4537 - accuracy: 0.0092 - val_loss: 0.4891 - val_accuracy: 0.0093\n",
            "Epoch 6/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4524 - accuracy: 0.0092 - val_loss: 0.4883 - val_accuracy: 0.0093\n",
            "Epoch 7/600\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.4508 - accuracy: 0.0085 - val_loss: 0.4895 - val_accuracy: 0.0093\n",
            "Epoch 8/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4501 - accuracy: 0.0090 - val_loss: 0.4890 - val_accuracy: 0.0093\n",
            "Epoch 9/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4489 - accuracy: 0.0091 - val_loss: 0.4899 - val_accuracy: 0.0042\n",
            "Epoch 10/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4480 - accuracy: 0.0087 - val_loss: 0.4910 - val_accuracy: 0.0093\n",
            "Epoch 11/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4475 - accuracy: 0.0087 - val_loss: 0.4906 - val_accuracy: 0.0092\n",
            "Epoch 12/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4467 - accuracy: 0.0082 - val_loss: 0.4922 - val_accuracy: 0.0093\n",
            "Epoch 13/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4464 - accuracy: 0.0088 - val_loss: 0.4926 - val_accuracy: 0.0093\n",
            "Epoch 14/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4458 - accuracy: 0.0087 - val_loss: 0.4929 - val_accuracy: 0.0042\n",
            "Epoch 15/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4450 - accuracy: 0.0070 - val_loss: 0.4943 - val_accuracy: 0.0093\n",
            "Epoch 16/600\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.4447 - accuracy: 0.0077 - val_loss: 0.4948 - val_accuracy: 0.0093\n",
            "Epoch 17/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4443 - accuracy: 0.0068 - val_loss: 0.4956 - val_accuracy: 0.0042\n",
            "Epoch 18/600\n",
            "32/32 [==============================] - 62s 2s/step - loss: 0.4441 - accuracy: 0.0060 - val_loss: 0.4970 - val_accuracy: 0.0093\n",
            "Epoch 19/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4437 - accuracy: 0.0070 - val_loss: 0.4982 - val_accuracy: 0.0042\n",
            "Epoch 20/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4435 - accuracy: 0.0059 - val_loss: 0.4988 - val_accuracy: 0.0092\n",
            "Epoch 21/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4433 - accuracy: 0.0052 - val_loss: 0.4997 - val_accuracy: 0.0092\n",
            "Epoch 22/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4431 - accuracy: 0.0061 - val_loss: 0.5005 - val_accuracy: 0.0042\n",
            "Epoch 23/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4427 - accuracy: 0.0050 - val_loss: 0.5011 - val_accuracy: 0.0042\n",
            "Epoch 24/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4423 - accuracy: 0.0048 - val_loss: 0.5025 - val_accuracy: 0.0092\n",
            "Epoch 25/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4422 - accuracy: 0.0052 - val_loss: 0.5034 - val_accuracy: 0.0042\n",
            "Epoch 26/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4418 - accuracy: 0.0046 - val_loss: 0.5049 - val_accuracy: 0.0042\n",
            "Epoch 27/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4417 - accuracy: 0.0037 - val_loss: 0.5050 - val_accuracy: 0.0042\n",
            "Epoch 28/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4418 - accuracy: 0.0037 - val_loss: 0.5064 - val_accuracy: 0.0042\n",
            "Epoch 29/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4416 - accuracy: 0.0045 - val_loss: 0.5072 - val_accuracy: 0.0042\n",
            "Epoch 30/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4415 - accuracy: 0.0037 - val_loss: 0.5080 - val_accuracy: 0.0042\n",
            "Epoch 31/600\n",
            "32/32 [==============================] - 62s 2s/step - loss: 0.4411 - accuracy: 0.0036 - val_loss: 0.5097 - val_accuracy: 0.0042\n",
            "Epoch 32/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4413 - accuracy: 0.0042 - val_loss: 0.5105 - val_accuracy: 0.0042\n",
            "Epoch 33/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4411 - accuracy: 0.0040 - val_loss: 0.5115 - val_accuracy: 0.0042\n",
            "Epoch 34/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4411 - accuracy: 0.0037 - val_loss: 0.5126 - val_accuracy: 0.0042\n",
            "Epoch 35/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4409 - accuracy: 0.0036 - val_loss: 0.5135 - val_accuracy: 0.0042\n",
            "Epoch 36/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4407 - accuracy: 0.0036 - val_loss: 0.5144 - val_accuracy: 0.0042\n",
            "Epoch 37/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4405 - accuracy: 0.0037 - val_loss: 0.5156 - val_accuracy: 0.0042\n",
            "Epoch 38/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4405 - accuracy: 0.0038 - val_loss: 0.5164 - val_accuracy: 0.0042\n",
            "Epoch 39/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4404 - accuracy: 0.0039 - val_loss: 0.5168 - val_accuracy: 0.0042\n",
            "Epoch 40/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4400 - accuracy: 0.0037 - val_loss: 0.5186 - val_accuracy: 0.0092\n",
            "Epoch 41/600\n",
            "32/32 [==============================] - 62s 2s/step - loss: 0.4401 - accuracy: 0.0043 - val_loss: 0.5195 - val_accuracy: 0.0042\n",
            "Epoch 42/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4399 - accuracy: 0.0043 - val_loss: 0.5205 - val_accuracy: 0.0042\n",
            "Epoch 43/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4399 - accuracy: 0.0041 - val_loss: 0.5208 - val_accuracy: 0.0042\n",
            "Epoch 44/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4398 - accuracy: 0.0036 - val_loss: 0.5222 - val_accuracy: 0.0042\n",
            "Epoch 45/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4397 - accuracy: 0.0036 - val_loss: 0.5229 - val_accuracy: 0.0042\n",
            "Epoch 46/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4395 - accuracy: 0.0036 - val_loss: 0.5243 - val_accuracy: 0.0042\n",
            "Epoch 47/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4395 - accuracy: 0.0036 - val_loss: 0.5249 - val_accuracy: 0.0042\n",
            "Epoch 48/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4395 - accuracy: 0.0036 - val_loss: 0.5260 - val_accuracy: 0.0042\n",
            "Epoch 49/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4396 - accuracy: 0.0039 - val_loss: 0.5266 - val_accuracy: 0.0042\n",
            "Epoch 50/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4393 - accuracy: 0.0036 - val_loss: 0.5277 - val_accuracy: 0.0042\n",
            "Epoch 51/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4393 - accuracy: 0.0036 - val_loss: 0.5290 - val_accuracy: 0.0042\n",
            "Epoch 52/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4394 - accuracy: 0.0036 - val_loss: 0.5295 - val_accuracy: 0.0042\n",
            "Epoch 53/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4394 - accuracy: 0.0036 - val_loss: 0.5303 - val_accuracy: 0.0042\n",
            "Epoch 54/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4391 - accuracy: 0.0037 - val_loss: 0.5321 - val_accuracy: 0.0042\n",
            "Epoch 55/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4389 - accuracy: 0.0036 - val_loss: 0.5329 - val_accuracy: 0.0042\n",
            "Epoch 56/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4389 - accuracy: 0.0035 - val_loss: 0.5337 - val_accuracy: 0.0042\n",
            "Epoch 57/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4390 - accuracy: 0.0037 - val_loss: 0.5343 - val_accuracy: 0.0042\n",
            "Epoch 58/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4389 - accuracy: 0.0036 - val_loss: 0.5353 - val_accuracy: 0.0042\n",
            "Epoch 59/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4388 - accuracy: 0.0035 - val_loss: 0.5366 - val_accuracy: 0.0042\n",
            "Epoch 60/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4388 - accuracy: 0.0036 - val_loss: 0.5370 - val_accuracy: 0.0042\n",
            "Epoch 61/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4389 - accuracy: 0.0036 - val_loss: 0.5378 - val_accuracy: 0.0042\n",
            "Epoch 62/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4387 - accuracy: 0.0037 - val_loss: 0.5389 - val_accuracy: 0.0042\n",
            "Epoch 63/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4388 - accuracy: 0.0040 - val_loss: 0.5398 - val_accuracy: 0.0042\n",
            "Epoch 64/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4389 - accuracy: 0.0039 - val_loss: 0.5403 - val_accuracy: 0.0042\n",
            "Epoch 65/600\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.4389 - accuracy: 0.0036 - val_loss: 0.5411 - val_accuracy: 0.0042\n",
            "Epoch 66/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4387 - accuracy: 0.0036 - val_loss: 0.5422 - val_accuracy: 0.0042\n",
            "Epoch 67/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4389 - accuracy: 0.0039 - val_loss: 0.5425 - val_accuracy: 0.0042\n",
            "Epoch 68/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4387 - accuracy: 0.0036 - val_loss: 0.5435 - val_accuracy: 0.0042\n",
            "Epoch 69/600\n",
            "32/32 [==============================] - 57s 2s/step - loss: 0.4386 - accuracy: 0.0036 - val_loss: 0.5425 - val_accuracy: 0.0043\n",
            "Epoch 70/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4390 - accuracy: 0.0039 - val_loss: 0.5457 - val_accuracy: 0.0042\n",
            "Epoch 71/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4386 - accuracy: 0.0036 - val_loss: 0.5466 - val_accuracy: 0.0042\n",
            "Epoch 72/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4387 - accuracy: 0.0037 - val_loss: 0.5468 - val_accuracy: 0.0042\n",
            "Epoch 73/600\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.4386 - accuracy: 0.0036 - val_loss: 0.5479 - val_accuracy: 0.0042\n",
            "Epoch 74/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4388 - accuracy: 0.0042 - val_loss: 0.5485 - val_accuracy: 0.0042\n",
            "Epoch 75/600\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.4387 - accuracy: 0.0036 - val_loss: 0.5491 - val_accuracy: 0.0042\n",
            "Epoch 76/600\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.4388 - accuracy: 0.0036 - val_loss: 0.5499 - val_accuracy: 0.0042\n",
            "Epoch 77/600\n",
            "29/32 [==========================>...] - ETA: 5s - loss: 0.4455 - accuracy: 0.0043"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-745eed32828a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temporal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HN8rtwql9tKv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CHATBOT2.ipynb",
      "provenance": [],
      "mount_file_id": "1NLk9_GncXNp4KQkZcO5NUv6HEj5lX9vZ",
      "authorship_tag": "ABX9TyMkoizCzKR0i+DeOhk87CvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}