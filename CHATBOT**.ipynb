{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awannabecs/PublicTensorflowRepository/blob/main/CHATBOT**.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### import the will-be-needed modules ####\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "WaCfxSoyIRSm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### load the data ####\n",
        "data_path =  \"/content/human_text.txt\"\n",
        "data_path2 = \"/content/robot_text.txt\""
      ],
      "metadata": {
        "id": "32MkE77-Jq6Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path, mode=\"r\",encoding=\"utf-8\") as f :\n",
        "  lines = f.read().split(\"\\n\")\n",
        "\n",
        "with open(data_path2, mode=\"r\", encoding=\"utf-8\") as f :\n",
        "  lines2 = f.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "jAvdkcG5Ksst"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "\n",
        "pairs = list(zip(lines,lines2))\n",
        "\n",
        "random.shuffle(pairs)"
      ],
      "metadata": {
        "id": "wSyFx1hzL1GT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "\n",
        "for line in pairs[:400]:\n",
        "  input_doc, target_doc = line[0],line[1]\n",
        "  input_docs.append(input_doc)\n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ],
      "metadata": {
        "id": "ij3bnobqP_S5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())"
      ],
      "metadata": {
        "id": "A2BbCEEpTD5h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum length of sentences in input and target documents\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n"
      ],
      "metadata": {
        "id": "fQ8KRDLQYTY4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n"
      ],
      "metadata": {
        "id": "zchf7YvKZHrN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float16')\n"
      ],
      "metadata": {
        "id": "Y8RZRCu_ZMLW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float16')"
      ],
      "metadata": {
        "id": "ndexpbeDZSCi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float16')\n"
      ],
      "metadata": {
        "id": "OH3Lu1YcZWAl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        # Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1"
      ],
      "metadata": {
        "id": "yh6WYCidZbAn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 50\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "knF1zRit6EsS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the random seed#\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('mychatnotmodel_1')"
      ],
      "metadata": {
        "id": "v6K26xjT76jm",
        "outputId": "23c69b5e-c0d8-43df-9118-f06676b06f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 27s 735ms/step - loss: 0.7842 - accuracy: 0.0131 - val_loss: 0.6120 - val_accuracy: 0.0130\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 23s 706ms/step - loss: 0.7492 - accuracy: 0.0145 - val_loss: 0.6162 - val_accuracy: 0.0130\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 22s 695ms/step - loss: 0.7464 - accuracy: 0.0146 - val_loss: 0.6197 - val_accuracy: 0.0130\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 23s 723ms/step - loss: 0.7442 - accuracy: 0.0147 - val_loss: 0.6216 - val_accuracy: 0.0130\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 23s 728ms/step - loss: 0.7424 - accuracy: 0.0147 - val_loss: 0.6283 - val_accuracy: 0.0139\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 22s 692ms/step - loss: 0.7422 - accuracy: 0.0147 - val_loss: 0.6275 - val_accuracy: 0.0130\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 22s 692ms/step - loss: 0.7405 - accuracy: 0.0148 - val_loss: 0.6324 - val_accuracy: 0.0130\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 23s 709ms/step - loss: 0.7398 - accuracy: 0.0146 - val_loss: 0.6347 - val_accuracy: 0.0130\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 22s 695ms/step - loss: 0.7399 - accuracy: 0.0148 - val_loss: 0.6372 - val_accuracy: 0.0130\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 22s 698ms/step - loss: 0.7393 - accuracy: 0.0147 - val_loss: 0.6410 - val_accuracy: 0.0130\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 22s 701ms/step - loss: 0.7384 - accuracy: 0.0148 - val_loss: 0.6441 - val_accuracy: 0.0130\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 22s 689ms/step - loss: 0.7381 - accuracy: 0.0147 - val_loss: 0.6484 - val_accuracy: 0.0130\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 23s 710ms/step - loss: 0.7370 - accuracy: 0.0148 - val_loss: 0.6501 - val_accuracy: 0.0130\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 22s 693ms/step - loss: 0.7365 - accuracy: 0.0148 - val_loss: 0.6535 - val_accuracy: 0.0130\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 22s 699ms/step - loss: 0.7362 - accuracy: 0.0147 - val_loss: 0.6569 - val_accuracy: 0.0130\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 22s 705ms/step - loss: 0.7358 - accuracy: 0.0147 - val_loss: 0.6617 - val_accuracy: 0.0130\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 22s 696ms/step - loss: 0.7356 - accuracy: 0.0145 - val_loss: 0.6634 - val_accuracy: 0.0130\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 22s 696ms/step - loss: 0.7347 - accuracy: 0.0147 - val_loss: 0.6658 - val_accuracy: 0.0130\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 22s 704ms/step - loss: 0.7348 - accuracy: 0.0148 - val_loss: 0.6693 - val_accuracy: 0.0130\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 22s 697ms/step - loss: 0.7343 - accuracy: 0.0147 - val_loss: 0.6711 - val_accuracy: 0.0130\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 22s 700ms/step - loss: 0.7337 - accuracy: 0.0146 - val_loss: 0.6757 - val_accuracy: 0.0042\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 22s 699ms/step - loss: 0.7336 - accuracy: 0.0142 - val_loss: 0.6786 - val_accuracy: 0.0130\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 22s 699ms/step - loss: 0.7334 - accuracy: 0.0144 - val_loss: 0.6817 - val_accuracy: 0.0130\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 23s 710ms/step - loss: 0.7333 - accuracy: 0.0147 - val_loss: 0.6847 - val_accuracy: 0.0130\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 22s 704ms/step - loss: 0.7337 - accuracy: 0.0146 - val_loss: 0.6877 - val_accuracy: 0.0130\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 22s 702ms/step - loss: 0.7334 - accuracy: 0.0139 - val_loss: 0.6896 - val_accuracy: 0.0130\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 22s 701ms/step - loss: 0.7331 - accuracy: 0.0144 - val_loss: 0.6929 - val_accuracy: 0.0042\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 22s 697ms/step - loss: 0.7332 - accuracy: 0.0137 - val_loss: 0.6958 - val_accuracy: 0.0130\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 23s 709ms/step - loss: 0.7649 - accuracy: 0.0126 - val_loss: 0.6997 - val_accuracy: 0.0139\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 22s 698ms/step - loss: 0.7780 - accuracy: 0.0130 - val_loss: 0.6962 - val_accuracy: 0.0138\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 22s 691ms/step - loss: 0.7566 - accuracy: 0.0141 - val_loss: 0.6947 - val_accuracy: 0.0138\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 22s 700ms/step - loss: 0.7620 - accuracy: 0.0129 - val_loss: 0.6895 - val_accuracy: 0.0120\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 22s 697ms/step - loss: 0.7468 - accuracy: 0.0139 - val_loss: 0.6890 - val_accuracy: 0.0139\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 22s 698ms/step - loss: 0.7412 - accuracy: 0.0139 - val_loss: 0.6926 - val_accuracy: 0.0139\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 23s 706ms/step - loss: 0.7396 - accuracy: 0.0136 - val_loss: 0.6932 - val_accuracy: 0.0139\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 23s 711ms/step - loss: 0.7362 - accuracy: 0.0137 - val_loss: 0.6922 - val_accuracy: 0.0139\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 23s 711ms/step - loss: 0.7356 - accuracy: 0.0130 - val_loss: 0.6950 - val_accuracy: 0.0130\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 22s 697ms/step - loss: 0.7347 - accuracy: 0.0133 - val_loss: 0.6984 - val_accuracy: 0.0130\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 22s 704ms/step - loss: 0.7348 - accuracy: 0.0125 - val_loss: 0.7008 - val_accuracy: 0.0139\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 23s 722ms/step - loss: 0.7344 - accuracy: 0.0125 - val_loss: 0.7056 - val_accuracy: 0.0032\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 22s 700ms/step - loss: 0.7348 - accuracy: 0.0121 - val_loss: 0.7063 - val_accuracy: 0.0139\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 23s 710ms/step - loss: 0.7340 - accuracy: 0.0125 - val_loss: 0.7087 - val_accuracy: 0.0139\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 22s 700ms/step - loss: 0.7344 - accuracy: 0.0131 - val_loss: 0.7091 - val_accuracy: 0.0042\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 23s 708ms/step - loss: 0.7339 - accuracy: 0.0135 - val_loss: 0.7109 - val_accuracy: 0.0139\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 23s 721ms/step - loss: 0.7345 - accuracy: 0.0128 - val_loss: 0.7134 - val_accuracy: 0.0139\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 22s 701ms/step - loss: 0.7342 - accuracy: 0.0133 - val_loss: 0.7157 - val_accuracy: 0.0130\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 22s 700ms/step - loss: 0.7349 - accuracy: 0.0132 - val_loss: 0.7155 - val_accuracy: 0.0042\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 23s 717ms/step - loss: 0.7345 - accuracy: 0.0137 - val_loss: 0.7154 - val_accuracy: 0.0130\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 23s 706ms/step - loss: 0.7342 - accuracy: 0.0135 - val_loss: 0.7188 - val_accuracy: 0.0139\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 22s 702ms/step - loss: 0.7349 - accuracy: 0.0135 - val_loss: 0.7192 - val_accuracy: 0.0139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: mychatnotmodel_1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: mychatnotmodel_1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0867991850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08679882d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jlXw04aWqYdX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CHATBOT2.ipynb",
      "provenance": [],
      "mount_file_id": "1NLk9_GncXNp4KQkZcO5NUv6HEj5lX9vZ",
      "authorship_tag": "ABX9TyO1TDuDiDpWbneISZHSt3lg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}