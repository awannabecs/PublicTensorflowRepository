{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awannabecs/PublicTensorflowRepository/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "SPEZDtsbBuhr"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.PorterStemmer()"
      ],
      "metadata": {
        "id": "9XWy7ZCBNkpA"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/DATASET/Sarcasm_Headlines_Dataset.json\") as f:\n",
        "  dataset = f.read()"
      ],
      "metadata": {
        "id": "6PA50K1gCVOl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = re.findall(r'''\\\"is_sarcastic\\\": (\\d)''',dataset)"
      ],
      "metadata": {
        "id": "ZJ9wlpY0C98O"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = re.findall(r'''\\\"headline\\\": \\\"(.+)\\\",''',dataset)"
      ],
      "metadata": {
        "id": "QGZYwJjrFHAk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_1 = [re.sub(\"[\\\\,\\.\\':\\?!\\-\\(\\)\\&%\\$\\\"\\d]|\\\\u00e9|'s\",\"\",sen) for sen in sentences]"
      ],
      "metadata": {
        "id": "Q8I53iT3HOYK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def listifier(text):\n",
        "#     return [i for i in text.split(\"\\n\") if i!=\"\"]\n",
        "# list_sentence = listifier(text) "
      ],
      "metadata": {
        "id": "oldQ3XflByz5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKENIZATION \n",
        "def tokenizer(list_sentence):\n",
        "    return set([word for sen in list_sentence for word in sen.split(\" \")])\n",
        "tokens = tokenizer(sentences_1)"
      ],
      "metadata": {
        "id": "zQpaUaLjBzmt"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DICTIONARIZE THE WORDS\n",
        "def dictionaizer(tokens):\n",
        "    dict_words = {}\n",
        "    for index,word in enumerate(tokens):\n",
        "        dict_words[word] = index\n",
        "    return dict_words\n",
        "dict_words = dictionaizer(tokens)"
      ],
      "metadata": {
        "id": "Y_ur_88GB3KD"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NUMBER OF WORDS BEFORE PREPROCESSING : 38245, 28993 ,20035\n",
        "tokens_1 = set([token for token in tokens])"
      ],
      "metadata": {
        "id": "q2O2xOFjH-n-"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_words_1 = dictionaizer(tokens_1)"
      ],
      "metadata": {
        "id": "5Ol836BXPmhV"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NUMBERIFY THE WORDS\n",
        "def numberifier(dict_words,list_sentence):\n",
        "    return [[dict_words[word] for word in sen.split(\" \")] for sen in list_sentence]\n",
        "list_numbers = numberifier(dict_words_1,sentences_1)"
      ],
      "metadata": {
        "id": "bCQhxLrCCHJt"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[8229, 20171, 11941, 22178, 27414, 8952, 9170, 12569],\n",
        "dict_words_1_rev = {}\n",
        "for key,value in dict_words_1.items():\n",
        "  dict_words_1_rev[value] = key "
      ],
      "metadata": {
        "id": "swhrfhFgQOIK"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def deunknownifier(dict_words,list_sentence):\n",
        "#     return [\" \".join([word if word in dict_words.keys() else \"<OOV>\"\n",
        "#             for word in sent.split(\" \")])\n",
        "#             for sent in list_sentence]\n",
        "# list_sentence_1 = deunknownifier(dict_words,list1)"
      ],
      "metadata": {
        "id": "wzcQd6tdCK7A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def paddifier(list_numbers):\n",
        "#     maxx = 0\n",
        "#     index = 0\n",
        "#     for i in list_numbers:\n",
        "#         if len(i) > maxx: \n",
        "#             index = list_numbers.index(i)\n",
        "#             maxx = len(i)\n",
        "#     padded = []\n",
        "#     for sen in list_numbers:\n",
        "#         for i in range(maxx-len(sen)):\n",
        "#             sen.insert(0,0)\n",
        "#         padded.append(sen)\n",
        "#     return padded\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "# paddifier(list_numbers_1)\n"
      ],
      "metadata": {
        "id": "dNGJwydxCOIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1ylOUYHnEzcWHzrVYn7pvYXrfLm3YkqYG",
      "authorship_tag": "ABX9TyNDx+HIfUZTdHO5tHiaOOE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}